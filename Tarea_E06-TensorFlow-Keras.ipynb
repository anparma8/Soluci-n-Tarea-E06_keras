{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 06\n",
    "# TensorFlow and Keras\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn.datasets.samples_generator import make_moons\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper functions to inline visualization of computing graphs\n",
    "# Extracted from: \n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "\n",
    "# Functions for plotting 2D data and decision regions\n",
    "\n",
    "def plot_data(X, y):\n",
    "    y_unique = np.unique(y)\n",
    "    colors = pl.cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
    "    for this_y, color in zip(y_unique, colors):\n",
    "        this_X = X[y == this_y]\n",
    "        pl.scatter(this_X[:, 0], this_X[:, 1],  c=color,\n",
    "                    alpha=0.5, edgecolor='k',\n",
    "                    label=\"Class %s\" % this_y)\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Data\")\n",
    "\n",
    "def plot_decision_region(X, pred_fun):\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "    min_x = min_x - (max_x - min_x) * 0.05\n",
    "    max_x = max_x + (max_x - min_x) * 0.05\n",
    "    min_y = min_y - (max_y - min_y) * 0.05\n",
    "    max_y = max_y + (max_y - min_y) * 0.05\n",
    "    x_vals = np.linspace(min_x, max_x, 30)\n",
    "    y_vals = np.linspace(min_y, max_y, 30)\n",
    "    XX, YY = np.meshgrid(x_vals, y_vals)\n",
    "    grid_r, grid_c = XX.shape\n",
    "    ZZ = np.zeros((grid_r, grid_c))\n",
    "    for i in range(grid_r):\n",
    "        for j in range(grid_c):\n",
    "            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n",
    "    pl.contourf(XX, YY, ZZ, 30, cmap = pl.cm.coolwarm, vmin= 0, vmax=1)\n",
    "    pl.colorbar()\n",
    "    pl.xlabel(\"x\")\n",
    "    pl.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multilayer neural network in TensorFlow\n",
    "\n",
    "You need to create a neural network model in TF that is able to discriminate the two classes in the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAF1CAYAAADBdGLoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAiCYDL+P9o72u+MhaYgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d147711a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y = make_moons(n_samples=1000, noise= 0.2, random_state=3)\n",
    "x_train = X[:500]\n",
    "x_test  = X[500:]\n",
    "y_train = Y[:500]\n",
    "y_test  = Y[500:]\n",
    "\n",
    "pl.figure(figsize=(8, 6))\n",
    "plot_data(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this you will need to create a neural network with one hidden layer. You cannot use prebuilt models \n",
    "such as those in `tf.estimator`. **Hint**: extend the logistic regression example from the TensorFlow handout. \n",
    "\n",
    "Your answer must contain the following:\n",
    "* A visualization of the CG of the model.\n",
    "* A visualization of the decision region along with the test data.\n",
    "* A snapshot from TensorBoard that shows the evolution of the training and test loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.12406661616262515&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;hidden_layer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden_layer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;hidden_layer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden_layer/random_normal/mul&quot;\\n  input: &quot;hidden_layer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/weights_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/weights_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden_layer/weights_1&quot;\\n  input: &quot;hidden_layer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer/weights_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/weights_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden_layer/weights_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer/weights_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal_1/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal_1/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal_1/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;hidden_layer/random_normal_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden_layer/random_normal_1/RandomStandardNormal&quot;\\n  input: &quot;hidden_layer/random_normal_1/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/random_normal_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden_layer/random_normal_1/mul&quot;\\n  input: &quot;hidden_layer/random_normal_1/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/bias_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/bias_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden_layer/bias_1&quot;\\n  input: &quot;hidden_layer/random_normal_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer/bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/bias_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden_layer/bias_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer/bias_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/transpose/Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/transpose/sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/transpose/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden_layer/transpose/Rank&quot;\\n  input: &quot;hidden_layer/transpose/sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/transpose/Range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/transpose/Range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/transpose/Range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;hidden_layer/transpose/Range/start&quot;\\n  input: &quot;hidden_layer/transpose/Rank&quot;\\n  input: &quot;hidden_layer/transpose/Range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/transpose/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden_layer/transpose/sub&quot;\\n  input: &quot;hidden_layer/transpose/Range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;hidden_layer/transpose/sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;hidden_layer/weights_1/read&quot;\\n  input: &quot;hidden_layer/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden_layer/MatMul&quot;\\n  input: &quot;hidden_layer/bias_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer/sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;hidden_layer/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;inference/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;inference/random_normal/RandomStandardNormal&quot;\\n  input: &quot;inference/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;inference/random_normal/mul&quot;\\n  input: &quot;inference/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;inference/weights&quot;\\n  input: &quot;inference/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@inference/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;inference/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@inference/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/bias/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;inference/bias&quot;\\n  input: &quot;inference/bias/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@inference/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;inference/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@inference/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;inference/weights/read&quot;\\n  input: &quot;hidden_layer/sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;inference/MatMul&quot;\\n  input: &quot;inference/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inference/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;inference/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  input: &quot;loss/logistic_loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss/logistic_loss/GreaterEqual&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  input: &quot;loss/logistic_loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss/logistic_loss/GreaterEqual&quot;\\n  input: &quot;loss/logistic_loss/Neg&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss/logistic_loss/Select&quot;\\n  input: &quot;loss/logistic_loss/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss/Exp&quot;\\n  op: &quot;Exp&quot;\\n  input: &quot;loss/logistic_loss/Select_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss/Log1p&quot;\\n  op: &quot;Log1p&quot;\\n  input: &quot;loss/logistic_loss/Exp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/logistic_loss&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss/logistic_loss/sub&quot;\\n  input: &quot;loss/logistic_loss/Log1p&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;loss/logistic_loss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;loss/range/start&quot;\\n  input: &quot;loss/Rank&quot;\\n  input: &quot;loss/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/logistic_loss&quot;\\n  input: &quot;loss/range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/logistic_loss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss/range&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/add&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/mod&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/range/start&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Size&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/range&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/mod&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Shape&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/DynamicStitch&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Shape&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/logistic_loss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Shape_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Shape_3&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Maximum_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Maximum_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Maximum_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/floordiv_1&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Maximum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/floordiv_1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/logistic_loss/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/logistic_loss/Log1p&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/Shape&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/Sum&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/Mean_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/Sum_1&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss_grad/Reshape&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/Reshape&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/logistic_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/logistic_loss/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/Shape&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/Sum&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/Neg&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/Reshape&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Log1p_grad/add/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Log1p_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Log1p_grad/add/x&quot;\\n  input: &quot;loss/logistic_loss/Exp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Log1p_grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Log1p_grad/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Log1p_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/logistic_loss_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Log1p_grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss/logistic_loss/GreaterEqual&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss/logistic_loss/GreaterEqual&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_grad/zeros_like&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/Select_grad/Select&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_grad/Select&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_grad/Select_1&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Shape&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Mul&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Sum&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Mul_1&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Sum_1&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Reshape&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Exp_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Log1p_grad/mul&quot;\\n  input: &quot;loss/logistic_loss/Exp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_1_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/logistic_loss/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_1_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss/logistic_loss/GreaterEqual&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Exp_grad/mul&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_1_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_1_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss/logistic_loss/GreaterEqual&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_1_grad/zeros_like&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Exp_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/Select_1_grad/Select&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/Select_1_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_1_grad/Select&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Select_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_1_grad/Select_1&quot;\\n  input: &quot;^train/gradients/loss/logistic_loss/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/logistic_loss/Neg_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Select_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train/gradients/loss/logistic_loss/Neg_grad/Neg&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/logistic_loss/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;inference/Sigmoid&quot;\\n  input: &quot;train/gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;inference/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/inference/add_grad/Shape&quot;\\n  input: &quot;train/gradients/inference/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/inference/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;train/gradients/inference/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/inference/add_grad/Sum&quot;\\n  input: &quot;train/gradients/inference/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/inference/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;train/gradients/inference/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/inference/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/inference/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/inference/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/inference/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/inference/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/inference/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/inference/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/inference/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/inference/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/inference/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/inference/add_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden_layer/sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;inference/weights/read&quot;\\n  input: &quot;train/gradients/inference/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/inference/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/inference/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/inference/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/inference/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/inference/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/inference/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/inference/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/inference/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/inference/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/inference/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;hidden_layer/sigmoid&quot;\\n  input: &quot;train/gradients/inference/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hidden_layer/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\n\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/Shape&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/hidden_layer/sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/Sum&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/hidden_layer/sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/hidden_layer/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/hidden_layer/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/hidden_layer/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/hidden_layer/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/hidden_layer/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/hidden_layer/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden_layer/transpose&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;hidden_layer/weights_1/read&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/hidden_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/hidden_layer/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/hidden_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/hidden_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/hidden_layer/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/hidden_layer/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/hidden_layer/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/hidden_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/hidden_layer/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden_layer/weights_1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden_layer/weights_1&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/hidden_layer/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer/weights_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden_layer/bias_1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden_layer/bias_1&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/hidden_layer/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer/bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_inference/weights/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;inference/weights&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/inference/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@inference/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_inference/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;inference/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/inference/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@inference/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_hidden_layer/bias_1/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden_layer/weights_1/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_inference/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_inference/weights/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden_layer/bias_1/Assign&quot;\\n  input: &quot;^hidden_layer/weights_1/Assign&quot;\\n  input: &quot;^inference/bias/Assign&quot;\\n  input: &quot;^inference/weights/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.12406661616262515&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "numN = 10\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #DATOS ENTRADA:\n",
    "    x = tf.placeholder(tf.float32,shape=[None,2]) #Los datos de entrenamiento son parejas. None representa el total de filas y es None pq en este punto no se sabe el tamao\n",
    "    y_true = tf.placeholder(tf.float32,shape=None)\n",
    "           \n",
    "    with tf.name_scope('hidden_layer') as scope: \n",
    "        w1 = tf.Variable(tf.random_normal([numN,2]),dtype=tf.float32,name='weights_1')\n",
    "        b1 = tf.Variable(tf.random_normal([numN,1]),dtype=tf.float32,name='bias_1') \n",
    "   \n",
    "        #h = tf.matmul(w_1,tf.transpose(x)) + b1\n",
    "        h = tf.sigmoid(tf.matmul(w1,tf.transpose(x)) + b1, name='sigmoid') #brosfcasting\n",
    "   \n",
    "    \n",
    "    #MODELO INFERENCIA \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable(tf.random_normal([1,numN]),dtype=tf.float32,name='weights')\n",
    "        b = tf.Variable(0,dtype=tf.float32,name='bias') \n",
    "        y_pred = tf.sigmoid(tf.matmul(w,h) + b )\n",
    "    \n",
    "    \n",
    "    #FUNCION DE PERDIDA (SIGMOIDE)    \n",
    "    with tf.name_scope('loss') as scope: #calculo de la perdida\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred) #el sigmoide esta implicito en la funcion de perdida\n",
    "        loss = tf.reduce_mean(loss) #mean es el promedio de la funcion de perdida\n",
    "  \n",
    "   \n",
    "    #FUNCION ENTRENAMIENTO\n",
    "    with tf.name_scope('train') as scope: #proceso de entrenamiento\n",
    "        learning_rate = 1.0\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss) #minimiza la funcion de perdida\n",
    "\n",
    "    init = tf.global_variables_initializer() #inicializacion de variables. hay que hacerlo siempre\n",
    "\n",
    "show_graph(graph.as_graph_def()) #visualization of the CG of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d148b354e0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFECAYAAAAKp2bdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIW2iIhIhlBoi4iIZIj/D5ogUM5odRbiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d148eceba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#num_epochs = 500\n",
    "#losses = []\n",
    "\n",
    "#with graph.as_default():\n",
    "    #sess = tf.Session()\n",
    "    #sess.run(init)      \n",
    "    #for step in range(num_epochs):\n",
    "        #sess.run(train,{x: X, y_true: Y})\n",
    "        #if (step % 50 == 0):\n",
    "            #losses.append(sess.run(loss, {x: X, y_true: Y}))\n",
    "                       \n",
    "#pl.figure(figsize = (8,16/3))\n",
    "#pl.plot(losses)\n",
    "\n",
    "\n",
    "num_epochs = 1000\n",
    "losses = []\n",
    "\n",
    "with graph.as_default(): \n",
    "    sess = tf.Session()\n",
    "    sess.run(init)      \n",
    "    for step in range(num_epochs):\n",
    "        sess.run(train,{x: x_train, y_true: y_train}) \n",
    "        if (step % 50 == 0):\n",
    "            losses.append(sess.run(loss, {x: x_train, y_true: y_train})) \n",
    "                       \n",
    "pl.figure(figsize = (8,16/3)) \n",
    "pl.plot(losses) snapshot from TensorBoard that shows the evolution of the training and test loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.800447    1.504145  ]\n",
      " [-1.1243105   3.1553483 ]\n",
      " [-0.42809558 -0.13005285]\n",
      " [-0.6060563   0.7315314 ]\n",
      " [ 1.0599233   1.3459423 ]\n",
      " [-0.65360785  2.057188  ]\n",
      " [ 1.1691993   2.4016995 ]\n",
      " [ 0.86923134 -3.8415723 ]\n",
      " [-1.085275   -1.3017278 ]\n",
      " [-0.934176    2.6738217 ]]\n",
      "[[0.0002483]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAFfCAYAAABqXTT/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d148b25240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "with graph.as_default():\n",
    "    wval = sess.run(w1)\n",
    "    print(wval)\n",
    "    result = sess.run(y_pred, {x:np.array([[1,2]])}) \n",
    "    print(result)\n",
    "    def pred_fun(x1, x2):\n",
    "        xval = np.array([[x1, x2]])\n",
    "        return sigmoid(sess.run(y_pred,{x: xval}))\n",
    "\n",
    "pl.figure(figsize = (8,16/3))    \n",
    "plot_decision_region(X, pred_fun)  #visualization of the decision region along with the test data.\n",
    "plot_data(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Improving the Keras text classifier\n",
    "\n",
    "Your goal is to improve the performance of the text classifier in the Keras handout. This is are the things that you need to try:\n",
    "\n",
    "* Different activation functions for the hidden layer (https://keras.io/activations/)\n",
    "* Different optimizers (https://keras.io/optimizers/)\n",
    "* Add dropout between the hidden layer and the output layer (https://keras.io/layers/core/#dropout)\n",
    "* Different initializers for the dense layers (https://keras.io/initializers/)\n",
    "\n",
    "Try different combinations and report your findings at the end. Which configuration got the best accuracy in test?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#usar el cdigo de la ultima parte de la clase 11. Documentar. Que se us y cuales mejoraron. \n",
    "#usar relu, celu, tangente hiperbolica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n",
      "[1, 2, 149, 8, 25, 2, 400, 304, 200, 6, 337, 4, 342, 2, 2, 7, 2, 2, 9, 4, 342, 643, 2, 7, 2, 4, 88, 2, 31, 4, 384, 292, 211, 5, 2, 978, 220, 33, 851, 2, 11, 15, 9, 447, 7, 42, 92, 131, 276, 5, 156, 11, 15, 50, 33, 30, 2, 7, 2, 383, 29, 336, 25, 383, 29, 2, 94, 156, 4, 49, 8, 7, 788, 4, 88, 33, 2, 747, 11, 15, 197, 92, 222, 825, 5, 934, 11, 15, 2, 8, 17, 12]\n",
      "['', 'dlr', 'and', 'cts', '', '80', 'average', 'companies', 'in', 'income', 'of', 'make', '', '', 'said', '', '', 'a', 'of', 'make', '52', '', 'said', '', 'of', '1987', '', '2', 'of', 'sold', 'general', 'states', 'to', '', 'field', 'securities', 'was', 'agricultural', '', '3', 'it', 'a', '1988', 'said', 'as', 'april', '50', 'term', 'to', 'earlier', '3', 'it', 'but', 'was', 'with', '', 'said', '', 'previously', 'be', 'sell', 'cts', 'previously', 'be', '', 'more', 'earlier', 'of', 'which', 'and', 'said', 'commerce', 'of', '1987', 'was', '', 'august', '3', 'it', 'export', 'april', 'report', 'vice', 'to', 'beef', '3', 'it', '', 'and', '000', 'for']\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n",
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_21 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_21 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_22 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_22 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 2.4542 - acc: 0.3630 - val_loss: 2.3069 - val_acc: 0.4260\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 2.1809 - acc: 0.4397 - val_loss: 2.1788 - val_acc: 0.4750\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 109us/step - loss: 2.0693 - acc: 0.4876 - val_loss: 2.0863 - val_acc: 0.4905\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 1.9903 - acc: 0.5032 - val_loss: 2.0180 - val_acc: 0.5061\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 1.9276 - acc: 0.5163 - val_loss: 1.9608 - val_acc: 0.5150\n",
      "2246/2246 [==============================] - 0s 44us/step\n",
      "Test score: 1.9264661263697718\n",
      "Test accuracy: 0.5258236865804117\n"
     ]
    }
   ],
   "source": [
    "# Desarrollo del ejercicio\n",
    "# Se presenta a continuacin el Text Classifier Trained del notebook 11\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 1000\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n",
    "                                                         test_split=0.2)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "\n",
    "\n",
    "print(x_train[101])\n",
    "\n",
    "\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "num_words = max(word_index.values()) + 1\n",
    "words = ['']*num_words\n",
    "for word in word_index:\n",
    "    words[word_index[word]] = word\n",
    "print([words[i-2] for i in x_train[101][1:]])\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "\n",
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "#build a dense neural network with one hidden layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "#configure the learning task to use SGD as optimization:\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#train the model using a 0.1 training validation split:\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "#test the performance over the test set:\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probamos el Text Classifier con diferentes funciones de activacin para la capa oculta de la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_23 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_23 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_24 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_24 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 3.6315 - acc: 0.3475 - val_loss: 3.4569 - val_acc: 0.3315\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 135us/step - loss: 3.2789 - acc: 0.3540 - val_loss: 3.1575 - val_acc: 0.3315\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 3.0113 - acc: 0.3540 - val_loss: 2.9468 - val_acc: 0.3315\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 133us/step - loss: 2.8327 - acc: 0.3540 - val_loss: 2.8144 - val_acc: 0.3315\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 2.7230 - acc: 0.3540 - val_loss: 2.7342 - val_acc: 0.3315\n",
      "2246/2246 [==============================] - 0s 71us/step\n",
      "Test score: 2.6777455719687104\n",
      "Test accuracy: 0.36197684778237277\n"
     ]
    }
   ],
   "source": [
    "#Activacin Softmax\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_25 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_25 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_26 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_26 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 2.2565 - acc: 0.4924 - val_loss: 1.8610 - val_acc: 0.5551\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 1.6756 - acc: 0.5973 - val_loss: 1.6611 - val_acc: 0.6251\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 1.5081 - acc: 0.6493 - val_loss: 1.5442 - val_acc: 0.6596\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 108us/step - loss: 1.3945 - acc: 0.6828 - val_loss: 1.4635 - val_acc: 0.6863\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 1.3081 - acc: 0.7083 - val_loss: 1.4031 - val_acc: 0.6919\n",
      "2246/2246 [==============================] - 0s 49us/step\n",
      "Test score: 1.3849501707462573\n",
      "Test accuracy: 0.6910062333301891\n"
     ]
    }
   ],
   "source": [
    "#Activacin Elu\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_27 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_27 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_28 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_28 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 2.0383 - acc: 0.5135 - val_loss: 1.7053 - val_acc: 0.5951\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 1.5285 - acc: 0.6479 - val_loss: 1.5132 - val_acc: 0.6641\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 1.3548 - acc: 0.6980 - val_loss: 1.4037 - val_acc: 0.6919\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 1.2417 - acc: 0.7251 - val_loss: 1.3332 - val_acc: 0.7119\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 1.1571 - acc: 0.7439 - val_loss: 1.2804 - val_acc: 0.7297\n",
      "2246/2246 [==============================] - 0s 54us/step\n",
      "Test score: 1.267155531571576\n",
      "Test accuracy: 0.715939447933929\n"
     ]
    }
   ],
   "source": [
    "#Activacin Selu\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('selu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_29 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_29 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_30 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_30 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 2.2435 - acc: 0.4269 - val_loss: 2.0838 - val_acc: 0.4538\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 1.9222 - acc: 0.5175 - val_loss: 1.8973 - val_acc: 0.5306\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 1.7787 - acc: 0.5613 - val_loss: 1.7852 - val_acc: 0.5684\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 1.6724 - acc: 0.6027 - val_loss: 1.6961 - val_acc: 0.6129\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 1.5880 - acc: 0.6348 - val_loss: 1.6411 - val_acc: 0.6307\n",
      "2246/2246 [==============================] - 0s 54us/step\n",
      "Test score: 1.6143085803713846\n",
      "Test accuracy: 0.6353517364468408\n"
     ]
    }
   ],
   "source": [
    "#Activacin SoftPlus\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('softplus'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_31 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_31 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_32 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_32 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 2.4392 - acc: 0.4774 - val_loss: 2.0023 - val_acc: 0.5061\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 1.8181 - acc: 0.5517 - val_loss: 1.7842 - val_acc: 0.5628\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 114us/step - loss: 1.6574 - acc: 0.6068 - val_loss: 1.6748 - val_acc: 0.6229\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 1.5545 - acc: 0.6482 - val_loss: 1.5976 - val_acc: 0.6529\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 98us/step - loss: 1.4746 - acc: 0.6686 - val_loss: 1.5372 - val_acc: 0.6719\n",
      "2246/2246 [==============================] - 0s 52us/step\n",
      "Test score: 1.5168480972891287\n",
      "Test accuracy: 0.6638468388511152\n"
     ]
    }
   ],
   "source": [
    "#Activacin SoftSign\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('softsign'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_33 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_33 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_34 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_34 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 2.5045 - acc: 0.4482 - val_loss: 1.9989 - val_acc: 0.5061\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 1.7957 - acc: 0.5547 - val_loss: 1.7717 - val_acc: 0.5762\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 1.6195 - acc: 0.6178 - val_loss: 1.6481 - val_acc: 0.6407\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 1.4999 - acc: 0.6566 - val_loss: 1.5565 - val_acc: 0.6685\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 1.4058 - acc: 0.6823 - val_loss: 1.4894 - val_acc: 0.6841\n",
      "2246/2246 [==============================] - 0s 50us/step\n",
      "Test score: 1.4548309528710899\n",
      "Test accuracy: 0.6740872662776513\n"
     ]
    }
   ],
   "source": [
    "#Activacin Relu\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_35 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_35 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_36 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_36 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 2.2454 - acc: 0.4821 - val_loss: 1.8191 - val_acc: 0.5462\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 113us/step - loss: 1.6589 - acc: 0.6078 - val_loss: 1.6214 - val_acc: 0.6296\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 110us/step - loss: 1.4927 - acc: 0.6631 - val_loss: 1.5106 - val_acc: 0.6596\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 107us/step - loss: 1.3829 - acc: 0.6903 - val_loss: 1.4338 - val_acc: 0.6808\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 111us/step - loss: 1.3003 - acc: 0.7075 - val_loss: 1.3795 - val_acc: 0.6997\n",
      "2246/2246 [==============================] - 0s 44us/step\n",
      "Test score: 1.3715252313673336\n",
      "Test accuracy: 0.6954585930808569\n"
     ]
    }
   ],
   "source": [
    "#Activacin Tanh\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Activacin Sigmoid se aplic en el ejercicio inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_37 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_37 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_38 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_38 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 2.4607 - acc: 0.3582 - val_loss: 2.3594 - val_acc: 0.3393\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 115us/step - loss: 2.2431 - acc: 0.3922 - val_loss: 2.2595 - val_acc: 0.3782\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 118us/step - loss: 2.1468 - acc: 0.4401 - val_loss: 2.1718 - val_acc: 0.4372\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 2.0714 - acc: 0.4749 - val_loss: 2.1024 - val_acc: 0.4861\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 116us/step - loss: 2.0104 - acc: 0.4949 - val_loss: 2.0467 - val_acc: 0.4928\n",
      "2246/2246 [==============================] - 0s 50us/step\n",
      "Test score: 2.0003637643340224\n",
      "Test accuracy: 0.5102404274530742\n"
     ]
    }
   ],
   "source": [
    "#Activacin Hard_Sigmoid\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_39 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_39 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_40 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_40 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 2.1301 - acc: 0.5043 - val_loss: 1.8024 - val_acc: 0.5729\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 104us/step - loss: 1.6151 - acc: 0.6172 - val_loss: 1.6108 - val_acc: 0.6329\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 106us/step - loss: 1.4512 - acc: 0.6625 - val_loss: 1.4991 - val_acc: 0.6652\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 112us/step - loss: 1.3406 - acc: 0.6963 - val_loss: 1.4225 - val_acc: 0.6841\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 128us/step - loss: 1.2580 - acc: 0.7158 - val_loss: 1.3680 - val_acc: 0.6952\n",
      "2246/2246 [==============================] - 0s 52us/step\n",
      "Test score: 1.3489470891621318\n",
      "Test accuracy: 0.7012466607567251\n"
     ]
    }
   ],
   "source": [
    "#Activacin Linear\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('linear'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mejor Funcin de Activacin para la capa oculta result ser Selu con un Test Accuracy de 0.7159 y el peor result ser Softmax con un Test Accuracy de 0.3619\n"
     ]
    }
   ],
   "source": [
    "print ('La mejor Funcin de Activacin para la capa oculta result ser Selu con un Test Accuracy de 0.7159 y el peor result ser Softmax con un Test Accuracy de 0.3619')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probamos el Text Classifier con diferentes Optimizadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimizador SGD se aplic en el ejercicio inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_53 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_53 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_54 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_54 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 232us/step - loss: 1.5287 - acc: 0.6536 - val_loss: 1.2795 - val_acc: 0.7208\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 1.0248 - acc: 0.7797 - val_loss: 1.1291 - val_acc: 0.7586\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 0.8261 - acc: 0.8145 - val_loss: 1.0013 - val_acc: 0.7786\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 160us/step - loss: 0.6856 - acc: 0.8431 - val_loss: 0.9551 - val_acc: 0.8053\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 161us/step - loss: 0.5899 - acc: 0.8677 - val_loss: 0.9016 - val_acc: 0.8020\n",
      "2246/2246 [==============================] - 0s 53us/step\n",
      "Test score: 0.8685302812927871\n",
      "Test accuracy: 0.7867319679430098\n"
     ]
    }
   ],
   "source": [
    "#Optimizador RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_55 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_55 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_56 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_56 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 205us/step - loss: 1.3828 - acc: 0.6863 - val_loss: 1.2406 - val_acc: 0.7264\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.9996 - acc: 0.7831 - val_loss: 1.1293 - val_acc: 0.7575\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.8761 - acc: 0.8032 - val_loss: 1.0662 - val_acc: 0.7631\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 0.7972 - acc: 0.8178 - val_loss: 1.0256 - val_acc: 0.7686\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 0.7375 - acc: 0.8306 - val_loss: 1.0012 - val_acc: 0.7753\n",
      "2246/2246 [==============================] - 0s 52us/step\n",
      "Test score: 0.9594023393289595\n",
      "Test accuracy: 0.7751558325912734\n"
     ]
    }
   ],
   "source": [
    "#Optimizador Adagrad\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import Adagrad\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adagrad(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_57 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_57 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_58 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_58 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 258us/step - loss: 1.7126 - acc: 0.6005 - val_loss: 1.4271 - val_acc: 0.6986\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 196us/step - loss: 1.1971 - acc: 0.7317 - val_loss: 1.2320 - val_acc: 0.7308\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 205us/step - loss: 1.0115 - acc: 0.7726 - val_loss: 1.1447 - val_acc: 0.7553\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 2s 204us/step - loss: 0.8872 - acc: 0.8004 - val_loss: 1.0748 - val_acc: 0.7597\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 203us/step - loss: 0.7936 - acc: 0.8190 - val_loss: 1.0342 - val_acc: 0.7764\n",
      "2246/2246 [==============================] - 0s 55us/step\n",
      "Test score: 0.9979899330852505\n",
      "Test accuracy: 0.7689225289668765\n"
     ]
    }
   ],
   "source": [
    "#Optimizador Adadelta\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_59 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_59 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_60 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_60 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 253us/step - loss: 1.6242 - acc: 0.6275 - val_loss: 1.2908 - val_acc: 0.7208\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 189us/step - loss: 1.0336 - acc: 0.7752 - val_loss: 1.0825 - val_acc: 0.7697\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 183us/step - loss: 0.8154 - acc: 0.8143 - val_loss: 0.9838 - val_acc: 0.7831\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 185us/step - loss: 0.6654 - acc: 0.8470 - val_loss: 0.9358 - val_acc: 0.7953\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 197us/step - loss: 0.5585 - acc: 0.8753 - val_loss: 0.8862 - val_acc: 0.7942\n",
      "2246/2246 [==============================] - 0s 66us/step\n",
      "Test score: 0.8662788099406132\n",
      "Test accuracy: 0.7969723954226221\n"
     ]
    }
   ],
   "source": [
    "#Optimizador Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_61 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_61 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_62 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_62 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 215us/step - loss: 1.6625 - acc: 0.6178 - val_loss: 1.4073 - val_acc: 0.6897\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 1.1743 - acc: 0.7396 - val_loss: 1.2237 - val_acc: 0.7308\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 0.9920 - acc: 0.7819 - val_loss: 1.1279 - val_acc: 0.7564\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.8701 - acc: 0.8058 - val_loss: 1.0590 - val_acc: 0.7620\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 0.7763 - acc: 0.8223 - val_loss: 1.0075 - val_acc: 0.7753\n",
      "2246/2246 [==============================] - 0s 54us/step\n",
      "Test score: 0.9786124624318558\n",
      "Test accuracy: 0.7715939448172773\n"
     ]
    }
   ],
   "source": [
    "#Optimizador Adamax\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import Adamax\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adamax(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_63 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_63 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_64 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_64 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 255us/step - loss: 1.3910 - acc: 0.6856 - val_loss: 1.1101 - val_acc: 0.7475\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 168us/step - loss: 0.8098 - acc: 0.8136 - val_loss: 0.9452 - val_acc: 0.7853\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 167us/step - loss: 0.5889 - acc: 0.8629 - val_loss: 0.8830 - val_acc: 0.7920\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.4494 - acc: 0.8976 - val_loss: 0.8658 - val_acc: 0.8031\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 170us/step - loss: 0.3583 - acc: 0.9143 - val_loss: 0.9040 - val_acc: 0.7853\n",
      "2246/2246 [==============================] - 0s 54us/step\n",
      "Test score: 0.900044621682443\n",
      "Test accuracy: 0.7831700801424755\n"
     ]
    }
   ],
   "source": [
    "#Optimizador Nadam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Nadam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_69 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_69 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_70 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_70 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 180us/step - loss: 12.5824 - acc: 0.2160 - val_loss: 12.5502 - val_acc: 0.2214\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 12.6285 - acc: 0.2165 - val_loss: 12.5502 - val_acc: 0.2214\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 121us/step - loss: 12.6285 - acc: 0.2165 - val_loss: 12.5502 - val_acc: 0.2214\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 12.6285 - acc: 0.2165 - val_loss: 12.5502 - val_acc: 0.2214\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 105us/step - loss: 12.6285 - acc: 0.2165 - val_loss: 12.5502 - val_acc: 0.2214\n",
      "2246/2246 [==============================] - 0s 53us/step\n",
      "Test score: 12.71650271190667\n",
      "Test accuracy: 0.21104185218165628\n"
     ]
    }
   ],
   "source": [
    "#Optimizador TFOptimizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import TFOptimizer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=TFOptimizer(optimizer),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor Optimizador es Adam, pues resulta un Test Accuracy de 0.7969. El peor es TFOptimizer, con un Test Accuracy de 0.2110\n"
     ]
    }
   ],
   "source": [
    "print ('El mejor Optimizador es Adam, pues resulta un Test Accuracy de 0.7969. El peor es TFOptimizer, con un Test Accuracy de 0.2110')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probamos el Text Classifier con diferentes omisiones entre la capa oculta y la capa de salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#omisiones entre la capa oculta y la capa de salida: Dense y Activation se aplicaron en el ejercicio inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_92 (Dense)               (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_93 (Activation)     (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dropout_8 (Dropout)            (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_93 (Dense)               (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_94 (Activation)     (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 229us/step - loss: 2.6214 - acc: 0.3467 - val_loss: 2.3239 - val_acc: 0.3648\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 137us/step - loss: 2.3643 - acc: 0.4007 - val_loss: 2.2294 - val_acc: 0.3815\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 2.2715 - acc: 0.4271 - val_loss: 2.1458 - val_acc: 0.4761\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 132us/step - loss: 2.1920 - acc: 0.4523 - val_loss: 2.0871 - val_acc: 0.4483\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 136us/step - loss: 2.1357 - acc: 0.4617 - val_loss: 2.0307 - val_acc: 0.4850\n",
      "2246/2246 [==============================] - 0s 60us/step\n",
      "Test score: 1.985436279223842\n",
      "Test accuracy: 0.5142475512286753\n"
     ]
    }
   ],
   "source": [
    "#omisiones entre la capa oculta y la capa de salida: Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dropout entre la capa oculta y la capa de salida que arroja un mejor test Accuracy (0.5142) es de 0.5\n"
     ]
    }
   ],
   "source": [
    "print('El dropout entre la capa oculta y la capa de salida que arroja un mejor test Accuracy (0.5142) es de 0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probamos el Text Classifier con diferentes Inicializadores para las capas densas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_145 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_141 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_146 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_142 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 282us/step - loss: 2.4153 - acc: 0.3667 - val_loss: 2.2864 - val_acc: 0.4194\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 2.1637 - acc: 0.4524 - val_loss: 2.1571 - val_acc: 0.4527\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 2.0521 - acc: 0.4921 - val_loss: 2.0675 - val_acc: 0.4861\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 1.9731 - acc: 0.5084 - val_loss: 1.9963 - val_acc: 0.4972\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 1.9104 - acc: 0.5189 - val_loss: 1.9416 - val_acc: 0.5117\n",
      "2246/2246 [==============================] - 0s 74us/step\n",
      "Test score: 1.9086067952540764\n",
      "Test accuracy: 0.5320569902313467\n"
     ]
    }
   ],
   "source": [
    "#Inicializador RandomNormal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='random_normal', bias_initializer='Zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_147 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_143 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_148 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_144 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 285us/step - loss: 2.4464 - acc: 0.3604 - val_loss: 2.3150 - val_acc: 0.3793\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 2.1861 - acc: 0.4368 - val_loss: 2.1855 - val_acc: 0.4739\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 2.0743 - acc: 0.4872 - val_loss: 2.0935 - val_acc: 0.4939\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 1.9943 - acc: 0.5044 - val_loss: 2.0215 - val_acc: 0.5006\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 139us/step - loss: 1.9314 - acc: 0.5168 - val_loss: 1.9661 - val_acc: 0.5072\n",
      "2246/2246 [==============================] - 0s 73us/step\n",
      "Test score: 1.9260350621818754\n",
      "Test accuracy: 0.523152270730011\n"
     ]
    }
   ],
   "source": [
    "#Inicializador RandomUniform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='random_uniform', bias_initializer='Zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_149 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_145 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_150 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_146 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 308us/step - loss: 2.4599 - acc: 0.3580 - val_loss: 2.3018 - val_acc: 0.4427\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 166us/step - loss: 2.1625 - acc: 0.4464 - val_loss: 2.1622 - val_acc: 0.4805\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 164us/step - loss: 2.0486 - acc: 0.4928 - val_loss: 2.0690 - val_acc: 0.4850\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 160us/step - loss: 1.9684 - acc: 0.5096 - val_loss: 1.9977 - val_acc: 0.5072\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 1.9050 - acc: 0.5251 - val_loss: 1.9394 - val_acc: 0.5117\n",
      "2246/2246 [==============================] - 0s 72us/step\n",
      "Test score: 1.9061746053789093\n",
      "Test accuracy: 0.5218165628048106\n"
     ]
    }
   ],
   "source": [
    "#Inicializador TruncatedNormal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='truncated_normal', bias_initializer='Zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_151 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_147 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_152 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_148 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 298us/step - loss: 2.4239 - acc: 0.3582 - val_loss: 2.3089 - val_acc: 0.4138\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 2.1737 - acc: 0.4340 - val_loss: 2.1768 - val_acc: 0.4383\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 2.0634 - acc: 0.4813 - val_loss: 2.0848 - val_acc: 0.4928\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 1.9832 - acc: 0.5027 - val_loss: 2.0129 - val_acc: 0.4983\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 1.9206 - acc: 0.5153 - val_loss: 1.9552 - val_acc: 0.5161\n",
      "2246/2246 [==============================] - 0s 69us/step\n",
      "Test score: 1.9157614109246517\n",
      "Test accuracy: 0.5289403384058792\n"
     ]
    }
   ],
   "source": [
    "#Inicializador VarianceScaling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='VarianceScaling', bias_initializer='Zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_153 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_149 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_154 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_150 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 3s 319us/step - loss: 2.4159 - acc: 0.3637 - val_loss: 2.3297 - val_acc: 0.3682\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 2.1925 - acc: 0.4399 - val_loss: 2.2028 - val_acc: 0.4572\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 2.0819 - acc: 0.4913 - val_loss: 2.1092 - val_acc: 0.4872\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 1.9992 - acc: 0.5079 - val_loss: 2.0336 - val_acc: 0.4994\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 1.9343 - acc: 0.5173 - val_loss: 1.9789 - val_acc: 0.5061\n",
      "2246/2246 [==============================] - 0s 72us/step\n",
      "Test score: 1.9360153660217991\n",
      "Test accuracy: 0.5178094390292095\n"
     ]
    }
   ],
   "source": [
    "#Inicializador Orthogonal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='Orthogonal', bias_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_155 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_151 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_156 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_152 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 303us/step - loss: 2.4367 - acc: 0.3640 - val_loss: 2.3200 - val_acc: 0.3815\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 2.1834 - acc: 0.4380 - val_loss: 2.1897 - val_acc: 0.4883\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 2.0717 - acc: 0.4914 - val_loss: 2.0958 - val_acc: 0.4805\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 1.9893 - acc: 0.5066 - val_loss: 2.0275 - val_acc: 0.5017\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 1.9263 - acc: 0.5161 - val_loss: 1.9663 - val_acc: 0.5161\n",
      "2246/2246 [==============================] - 0s 73us/step\n",
      "Test score: 1.9234798803779554\n",
      "Test accuracy: 0.5191451469544099\n"
     ]
    }
   ],
   "source": [
    "#Inicializador Lecun_uniform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='lecun_uniform', bias_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_157 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_153 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_158 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_154 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 304us/step - loss: 2.4403 - acc: 0.3622 - val_loss: 2.3198 - val_acc: 0.3560\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 2.1887 - acc: 0.4257 - val_loss: 2.1850 - val_acc: 0.4839\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 2.0732 - acc: 0.4834 - val_loss: 2.0881 - val_acc: 0.4861\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 1.9903 - acc: 0.5004 - val_loss: 2.0141 - val_acc: 0.5017\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 140us/step - loss: 1.9244 - acc: 0.5184 - val_loss: 1.9576 - val_acc: 0.5139\n",
      "2246/2246 [==============================] - 0s 76us/step\n",
      "Test score: 1.9201781526805033\n",
      "Test accuracy: 0.5262689225554785\n"
     ]
    }
   ],
   "source": [
    "#Inicializador glorot_nornal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='glorot_normal', bias_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_159 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_155 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_160 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_156 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 309us/step - loss: 2.4213 - acc: 0.3668 - val_loss: 2.3097 - val_acc: 0.3704\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 147us/step - loss: 2.1747 - acc: 0.4507 - val_loss: 2.1767 - val_acc: 0.4772\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 2.0611 - acc: 0.4960 - val_loss: 2.0827 - val_acc: 0.4905\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 156us/step - loss: 1.9804 - acc: 0.5086 - val_loss: 2.0117 - val_acc: 0.5083\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 143us/step - loss: 1.9173 - acc: 0.5204 - val_loss: 1.9531 - val_acc: 0.5128\n",
      "2246/2246 [==============================] - 0s 71us/step\n",
      "Test score: 1.9145607181881967\n",
      "Test accuracy: 0.5280498664557456\n"
     ]
    }
   ],
   "source": [
    "#Inicializador glorot_uniform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_161 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_157 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_162 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_158 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 300us/step - loss: 2.4196 - acc: 0.3705 - val_loss: 2.2988 - val_acc: 0.3927\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 2.1727 - acc: 0.4469 - val_loss: 2.1797 - val_acc: 0.4160\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 2.0617 - acc: 0.4897 - val_loss: 2.0816 - val_acc: 0.4872\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 1.9795 - acc: 0.5080 - val_loss: 2.0111 - val_acc: 0.4983\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 141us/step - loss: 1.9160 - acc: 0.5192 - val_loss: 1.9523 - val_acc: 0.5083\n",
      "2246/2246 [==============================] - 0s 78us/step\n",
      "Test score: 1.913313192017675\n",
      "Test accuracy: 0.5262689225554785\n"
     ]
    }
   ],
   "source": [
    "#Inicializador he_normal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='he_normal', bias_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_163 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_159 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_164 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_160 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 3s 310us/step - loss: 2.4269 - acc: 0.3645 - val_loss: 2.3098 - val_acc: 0.4260\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 2.1827 - acc: 0.4428 - val_loss: 2.1913 - val_acc: 0.4327\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 2.0734 - acc: 0.4905 - val_loss: 2.0948 - val_acc: 0.4872\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 1.9932 - acc: 0.5049 - val_loss: 2.0265 - val_acc: 0.4917\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 1.9306 - acc: 0.5147 - val_loss: 1.9668 - val_acc: 0.5117\n",
      "2246/2246 [==============================] - 0s 75us/step\n",
      "Test score: 1.925545756559975\n",
      "Test accuracy: 0.5195903829294767\n"
     ]
    }
   ],
   "source": [
    "#Inicializador lecun_normal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='lecun_normal', bias_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_165 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_161 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_166 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_162 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 3s 310us/step - loss: 2.4803 - acc: 0.3523 - val_loss: 2.3123 - val_acc: 0.3471\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 2.1763 - acc: 0.4433 - val_loss: 2.1782 - val_acc: 0.4238\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 186us/step - loss: 2.0626 - acc: 0.4866 - val_loss: 2.0824 - val_acc: 0.4772\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 157us/step - loss: 1.9794 - acc: 0.5034 - val_loss: 2.0099 - val_acc: 0.5061\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 1.9146 - acc: 0.5187 - val_loss: 1.9493 - val_acc: 0.5106\n",
      "2246/2246 [==============================] - 0s 75us/step\n",
      "Test score: 1.9084340583397041\n",
      "Test accuracy: 0.5262689225554785\n"
     ]
    }
   ],
   "source": [
    "#Inicializador he_uniform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,),kernel_initializer='he_uniform', bias_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En general, todos los inicializadores generan Test Accuracy parecidos. Sin embargo, el mejor Inicializador es RandomNormal, pues genera un Test Accuracy = 0.5320.\n"
     ]
    }
   ],
   "source": [
    "print('En general, todos los inicializadores generan Test Accuracy parecidos. Sin embargo, el mejor Inicializador es RandomNormal, pues genera un Test Accuracy = 0.5320.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finalmente, despues de probar los diferentes argumentos solicitados, se potencializa el Test Classifier, con aquellos que\n",
    "#arrojaron mejores reultados en el Test Accuracy: Activacin Selu, Optimizador Adam, Dropout=0.5 y el inicializadorRandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_167 (Dense)              (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_163 (Activation)    (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dropout_9 (Dropout)            (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_168 (Dense)              (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_164 (Activation)    (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 3s 394us/step - loss: 1.4151 - acc: 0.6809 - val_loss: 1.0539 - val_acc: 0.7653\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 210us/step - loss: 0.7892 - acc: 0.8170 - val_loss: 0.9104 - val_acc: 0.7931\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 203us/step - loss: 0.5904 - acc: 0.8593 - val_loss: 0.9057 - val_acc: 0.8009\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 2s 196us/step - loss: 0.4723 - acc: 0.8862 - val_loss: 0.9094 - val_acc: 0.8042\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 195us/step - loss: 0.4064 - acc: 0.8994 - val_loss: 0.9288 - val_acc: 0.7976\n",
      "2246/2246 [==============================] - 0s 82us/step\n",
      "Test score: 0.9001445398729822\n",
      "Test accuracy: 0.7929652715939448\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,), kernel_initializer='random_normal', bias_initializer='Zeros'))\n",
    "model.add(Activation('selu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La configuracin dada anteriormente genera el mejor Accuracy en Test, que resulta ser 0.7929652715939448\n"
     ]
    }
   ],
   "source": [
    "print('La configuracin dada anteriormente genera el mejor Accuracy en Test, que resulta ser', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
